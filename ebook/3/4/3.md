# 3.4.3 2型语法

幸运的是，CF（2型）语法的解析算法相比于0型和1型要著名的多。使用CF和FS语法中几乎所有实用的解析都做过了，并且在上下午无关语法的解析中几乎所有遇到的问题都被解决了。这么大差距的原因可以在CF语法生成过程中找到：句子形式中的一个非终结符的演变是完全独立于其余非终结符的演变的，并且相反的是，在解析过程中，我们可以结合部分解析树而不理会它们的历史。在上下午相关语法中这些都不是正确的。

自顶向下和自底向上解析过程都很容易适用于CF语法。在下面的例子中，我们应使用简单的语法

![图1](../../img/3.4.3_1.png)

### 3.4.3.1 自顶向下CF语法解析

在自顶向下CF语法解析中，我们从起始符号入手，并尝试产生输出。这里的关键词是*预测*和*匹配*。句子形式中任何时候都有一个最左侧非终结符*A*，而解析器系统的尝试预测一个*A*的恰当的替代品，在这个位置的输入中一旦有兼容的符号被发现，那*A*的产物就应该开始了。这个最左侧的非终结符也被称为预测过程的目标。

想想图Fig 3.5中的例子，其中**Object**就是最左侧的非终结符，也就是“目标”。在这种情况下，解析器将首先预测**Object**的**the Noun**，然后会立即推翻这个替换项，因为**the**的位置被要求是一个**a**。接下来，解析器将会尝试**a Noun**，这个将会被暂时接受。**a**匹配上了，新的最左侧非终结符就成了**Noun**。当**Noun**最终生成了**dog**时，这个解析器就成功了。解析器将会为**Object**尝试第三次预测，**ProperName**；这个替换项不会被立即拒绝，因为解析器无法知道**ProperName**不能起始于一个**a**。它将在稍后阶段中失败。

![图2](../../img/3.4.3_2-Fig.3.5.png)

这种方法有两个严重的问题。虽然理论上，它可以处理任意的CF语法，但如果被单纯的照章办事的执行的话，可能会在一些语法中走到死循环中。这个可以通过使用一些特殊技术来避免掉，这在大多数自顶向下解析器中处理了；这个将在第6章中详细讲解。第二个问题是算法必须符合时间指数分布，因为任何一次预测都可能被证明是错误的，并且需要在反复试错中纠正。上面的例子显示了可以通过预处理语法来增加一些效率：其优势在于可以预先知道哪些记号可以开启**ProperName**，以避免预测注定会失败的替代项。这对于语法中的大多数非终结符来说是正确的，而且这种信息可以很容易的从语法中计算出来并存储在一个表中供解析中使用。对于一个合理的语法集合，可以实现一个线性时间依赖项，比如第8章将会解释的。

### 3.4.3.2 自底向上CF语法解析

In bottom-up CF parsing we start with the input and try to reduce it to the start symbol. Here the keywords are shift and reduce. When we are in the middle of the process, we have in our hands a sentential form reduced from the input. Somewhere in this sentential form there must be a segment (a substring) that was the result of the last production step that produced this sentential form. This segment corresponds to the right-hand side α of a production rule A→α and must now be reduced to A. The segment and the production rule together are called the handle of the sentential form, a quite fitting expression; see Figure 3.6. (When the production rule is obvious from the way the segment was found, the matching segment alone is often called the “handle”. We will usually follow this custom, but call the matching segment the handle segment when we feel that that is clearer.)

![图3](../../img/3.4.3_3-Fig.3.6.png)

The trick is to find the handle. It must be the right-hand side of a rule, so we start looking for such a right-hand side by shifting symbols from the sentential form into the internal administration. When we find a right-hand side we reduce it to its left-hand side and repeat the process, until only the start symbol is left. We will not always find the correct handle this way; if we err, we will get stuck further on, will have to undo some steps, shift in more symbols and try again. In Figure 3.6 we could have reduced the a Noun to Object, thereby boldly heading for a dead end.

There are essentially the same two problems with this approach as with the topdown technique. It may loop, and will do so on grammars with ε-rules: it will continue to find empty productions all over the place. This can be remedied by touching up the grammar. And it can take exponential time, since the correct identification of the handle may have to be done by trial and error. Again, doing preprocessing on the grammar often helps: it is easy to see from the grammar that Subject can be followed by chased, but Object cannot. So it is unprofitable to reduce a handle to Object if the next symbol is chased.